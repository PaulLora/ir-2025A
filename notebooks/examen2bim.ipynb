{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849354a7",
   "metadata": {},
   "source": [
    "# Recuperacion de la Informaicon\n",
    "# Examen Segundo Bimestre RI\n",
    "\n",
    "**Nombre:** Paul Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83c16d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /Users/paullora/Desktop/EPN/ir/ir-2025A/.venv/lib/python3.12/site-packages (from rank_bm25) (1.26.4)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56578d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342bcbb",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a37255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "titles = []\n",
    "identifiers = []\n",
    "with open(\"../data/examen/data.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            entry = json.loads(line)\n",
    "            title = entry.get(\"title\", \"\")\n",
    "            abstract = entry.get(\"abstract\", \"\")\n",
    "            identifier = entry.get(\"id\", \"\")\n",
    "            corpus.append(abstract)\n",
    "            titles.append(title)\n",
    "            identifiers.append(identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67aaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame({\n",
    "    \"identifier\": identifiers,\n",
    "    \"title\": titles,\n",
    "    \"raw\": corpus,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "141f8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_doc(doc):\n",
    "    words = word_tokenize(doc.lower())\n",
    "    words_filtered = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14378bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>title</th>\n",
       "      <th>raw</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>fully differential calculation perturbative qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>describe new algorithm k game colors use obtai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>evolution system described dark matter field f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>show determinant stirling cycle numbers counts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>paper show compute norm using dyadic grid resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27918</th>\n",
       "      <td>0710.0971</td>\n",
       "      <td>The Extending for Composite Skyrme Model</td>\n",
       "      <td>In this paper, we have extended the composit...</td>\n",
       "      <td>paper extended composite skyrme model proposed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27919</th>\n",
       "      <td>0710.0972</td>\n",
       "      <td>A Floer homology for exact contact embeddings</td>\n",
       "      <td>In this paper we construct the Floer homolog...</td>\n",
       "      <td>paper construct floer homology action function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27920</th>\n",
       "      <td>0710.0973</td>\n",
       "      <td>Modulation invariant bilinear T(1) theorem</td>\n",
       "      <td>We prove a T(1) theorem for bilinear singula...</td>\n",
       "      <td>prove theorem bilinear singular integral opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27921</th>\n",
       "      <td>0710.0974</td>\n",
       "      <td>Hawking radiation in GHS and non-extremal D1-D...</td>\n",
       "      <td>We apply the method of Banerjee and Kulkarni...</td>\n",
       "      <td>apply method banerjee kulkarni provide derivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27922</th>\n",
       "      <td>0710.0975</td>\n",
       "      <td>Renormalisation of quark bilinears with Nf=2 W...</td>\n",
       "      <td>We present results for the renormalisation c...</td>\n",
       "      <td>present results renormalisation constants bili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27923 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier                                              title  \\\n",
       "0      0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1      0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2      0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3      0704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4      0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "...          ...                                                ...   \n",
       "27918  0710.0971           The Extending for Composite Skyrme Model   \n",
       "27919  0710.0972      A Floer homology for exact contact embeddings   \n",
       "27920  0710.0973         Modulation invariant bilinear T(1) theorem   \n",
       "27921  0710.0974  Hawking radiation in GHS and non-extremal D1-D...   \n",
       "27922  0710.0975  Renormalisation of quark bilinears with Nf=2 W...   \n",
       "\n",
       "                                                     raw  \\\n",
       "0        A fully differential calculation in perturba...   \n",
       "1        We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2        The evolution of Earth-Moon system is descri...   \n",
       "3        We show that a determinant of Stirling cycle...   \n",
       "4        In this paper we show how to compute the $\\L...   \n",
       "...                                                  ...   \n",
       "27918    In this paper, we have extended the composit...   \n",
       "27919    In this paper we construct the Floer homolog...   \n",
       "27920    We prove a T(1) theorem for bilinear singula...   \n",
       "27921    We apply the method of Banerjee and Kulkarni...   \n",
       "27922    We present results for the renormalisation c...   \n",
       "\n",
       "                                               processed  \n",
       "0      fully differential calculation perturbative qu...  \n",
       "1      describe new algorithm k game colors use obtai...  \n",
       "2      evolution system described dark matter field f...  \n",
       "3      show determinant stirling cycle numbers counts...  \n",
       "4      paper show compute norm using dyadic grid resu...  \n",
       "...                                                  ...  \n",
       "27918  paper extended composite skyrme model proposed...  \n",
       "27919  paper construct floer homology action function...  \n",
       "27920  prove theorem bilinear singular integral opera...  \n",
       "27921  apply method banerjee kulkarni provide derivat...  \n",
       "27922  present results renormalisation constants bili...  \n",
       "\n",
       "[27923 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df['processed'] = corpus_df['raw'].apply(preprocess_doc)\n",
    "corpus_df['processed'] = corpus_df['processed'].str.replace(\"\\n\", \" \")\n",
    "corpus_df['processed'] = corpus_df['processed'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de4348",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "728f4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_processed_list = corpus_df['processed'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7412be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(corpus_processed_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732609b",
   "metadata": {},
   "source": [
    "### Indexacion TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95c7ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27913</th>\n",
       "      <th>27914</th>\n",
       "      <th>27915</th>\n",
       "      <th>27916</th>\n",
       "      <th>27917</th>\n",
       "      <th>27918</th>\n",
       "      <th>27919</th>\n",
       "      <th>27920</th>\n",
       "      <th>27921</th>\n",
       "      <th>27922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aadl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aadt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzgam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzgamma</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzh</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41207 rows Ã— 27923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9      \\\n",
       "aa         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aab        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aac        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadl       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadt       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "zz         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgam      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgamma    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzh        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzz        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         ...  27913  27914  27915  27916  27917  27918  27919  27920  27921  \\\n",
       "aa       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aab      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aac      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadl     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadt     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "zz       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgam    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgamma  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzh      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzz      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         27922  \n",
       "aa         0.0  \n",
       "aab        0.0  \n",
       "aac        0.0  \n",
       "aadl       0.0  \n",
       "aadt       0.0  \n",
       "...        ...  \n",
       "zz         0.0  \n",
       "zzgam      0.0  \n",
       "zzgamma    0.0  \n",
       "zzh        0.0  \n",
       "zzz        0.0  \n",
       "\n",
       "[41207 rows x 27923 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfidf_vectorizer_vectors.T.todense(), index=tfidf_vectorizer.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b301e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tfidf(query, top_k=10):\n",
    "    vertorized_query = tfidf_vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(vertorized_query, tfidf_vectorizer_vectors).flatten()\n",
    "    top_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "    return corpus_df.iloc[top_indices]['raw'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be560e",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eface95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_corpus = [text.split() for text in corpus_df[\"raw\"]] \n",
    "bm25 = BM25Okapi(bm25_corpus)\n",
    "\n",
    "def search_bm25(query, top_k=10):\n",
    "    query_tokens = preprocess_doc(query)\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    return corpus_df.iloc[top_indices]['raw'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3f296",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4791663f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>title</th>\n",
       "      <th>raw</th>\n",
       "      <th>processed</th>\n",
       "      <th>faiss_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>fully differential calculation perturbative qu...</td>\n",
       "      <td>[-0.13706283271312714, 0.012870294973254204, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>describe new algorithm k game colors use obtai...</td>\n",
       "      <td>[0.003494551870971918, 0.07694141566753387, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>evolution system described dark matter field f...</td>\n",
       "      <td>[-0.019724154844880104, -0.05407233163714409, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>show determinant stirling cycle numbers counts...</td>\n",
       "      <td>[-0.011817766353487968, 0.011769413948059082, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>paper show compute norm using dyadic grid resu...</td>\n",
       "      <td>[0.01388106681406498, 0.02092020958662033, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27918</th>\n",
       "      <td>0710.0971</td>\n",
       "      <td>The Extending for Composite Skyrme Model</td>\n",
       "      <td>In this paper, we have extended the composit...</td>\n",
       "      <td>paper extended composite skyrme model proposed...</td>\n",
       "      <td>[-0.06210463121533394, -0.0521075539290905, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27919</th>\n",
       "      <td>0710.0972</td>\n",
       "      <td>A Floer homology for exact contact embeddings</td>\n",
       "      <td>In this paper we construct the Floer homolog...</td>\n",
       "      <td>paper construct floer homology action function...</td>\n",
       "      <td>[-0.07222992926836014, 0.008860399946570396, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27920</th>\n",
       "      <td>0710.0973</td>\n",
       "      <td>Modulation invariant bilinear T(1) theorem</td>\n",
       "      <td>We prove a T(1) theorem for bilinear singula...</td>\n",
       "      <td>prove theorem bilinear singular integral opera...</td>\n",
       "      <td>[-0.0074160280637443066, -0.012459847144782543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27921</th>\n",
       "      <td>0710.0974</td>\n",
       "      <td>Hawking radiation in GHS and non-extremal D1-D...</td>\n",
       "      <td>We apply the method of Banerjee and Kulkarni...</td>\n",
       "      <td>apply method banerjee kulkarni provide derivat...</td>\n",
       "      <td>[-0.013154637068510056, 0.04781310260295868, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27922</th>\n",
       "      <td>0710.0975</td>\n",
       "      <td>Renormalisation of quark bilinears with Nf=2 W...</td>\n",
       "      <td>We present results for the renormalisation c...</td>\n",
       "      <td>present results renormalisation constants bili...</td>\n",
       "      <td>[-0.11150189489126205, -0.04424768313765526, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27923 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier                                              title  \\\n",
       "0      0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1      0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2      0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3      0704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4      0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "...          ...                                                ...   \n",
       "27918  0710.0971           The Extending for Composite Skyrme Model   \n",
       "27919  0710.0972      A Floer homology for exact contact embeddings   \n",
       "27920  0710.0973         Modulation invariant bilinear T(1) theorem   \n",
       "27921  0710.0974  Hawking radiation in GHS and non-extremal D1-D...   \n",
       "27922  0710.0975  Renormalisation of quark bilinears with Nf=2 W...   \n",
       "\n",
       "                                                     raw  \\\n",
       "0        A fully differential calculation in perturba...   \n",
       "1        We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2        The evolution of Earth-Moon system is descri...   \n",
       "3        We show that a determinant of Stirling cycle...   \n",
       "4        In this paper we show how to compute the $\\L...   \n",
       "...                                                  ...   \n",
       "27918    In this paper, we have extended the composit...   \n",
       "27919    In this paper we construct the Floer homolog...   \n",
       "27920    We prove a T(1) theorem for bilinear singula...   \n",
       "27921    We apply the method of Banerjee and Kulkarni...   \n",
       "27922    We present results for the renormalisation c...   \n",
       "\n",
       "                                               processed  \\\n",
       "0      fully differential calculation perturbative qu...   \n",
       "1      describe new algorithm k game colors use obtai...   \n",
       "2      evolution system described dark matter field f...   \n",
       "3      show determinant stirling cycle numbers counts...   \n",
       "4      paper show compute norm using dyadic grid resu...   \n",
       "...                                                  ...   \n",
       "27918  paper extended composite skyrme model proposed...   \n",
       "27919  paper construct floer homology action function...   \n",
       "27920  prove theorem bilinear singular integral opera...   \n",
       "27921  apply method banerjee kulkarni provide derivat...   \n",
       "27922  present results renormalisation constants bili...   \n",
       "\n",
       "                                        faiss_embeddings  \n",
       "0      [-0.13706283271312714, 0.012870294973254204, 0...  \n",
       "1      [0.003494551870971918, 0.07694141566753387, -0...  \n",
       "2      [-0.019724154844880104, -0.05407233163714409, ...  \n",
       "3      [-0.011817766353487968, 0.011769413948059082, ...  \n",
       "4      [0.01388106681406498, 0.02092020958662033, -0....  \n",
       "...                                                  ...  \n",
       "27918  [-0.06210463121533394, -0.0521075539290905, -0...  \n",
       "27919  [-0.07222992926836014, 0.008860399946570396, 0...  \n",
       "27920  [-0.0074160280637443066, -0.012459847144782543...  \n",
       "27921  [-0.013154637068510056, 0.04781310260295868, 0...  \n",
       "27922  [-0.11150189489126205, -0.04424768313765526, 0...  \n",
       "\n",
       "[27923 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(corpus_df[\"processed\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "corpus_df['faiss_embeddings'] = embeddings.tolist()\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_faiss(index, query, top_k=10):\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    _, indices = index.search(query_embedding, top_k)\n",
    "    return corpus_df.iloc[indices.flatten()]['raw'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeff117",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca627523",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Computer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto_tfidf = search_tfidf(query, top_k=5)\n",
    "contexto_bm25 = search_bm25(query, top_k=5)\n",
    "contexto_faiss = search_faiss(index, query, top_k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2c575c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  We study the flavor-changing-neutral-current process c to u mu+ mu- using 1.3\\nfb^-1 of p p bar collisions at sqrt(s) = 1.96 TeV recorded by the D0 detector\\noperating at the Fermilab Tevatron Collider. We see clear indications of the\\nDs+ and D+ to phi pi+ to mu+ mu- pi+ final states with significance greater\\nthan four standard deviations above background for the D+ state. We search for\\nthe continuum decay of D+ to pi+mu+mu- in the dimuon invariant mass spectrum\\naway from the phi resonance. We see no evidence of signal above background and\\nset a limit of B(D+ to pi+mu+mu-) < 3.9 x 10^-6 at the 90% C.L. This limit\\nplaces the most stringent constraint on new phenomena in the c to u mu+ mu-\\ntransition.\\n', '  A path from s to t on a polyhedral terrain is descending if the height of a\\npoint p never increases while we move p along the path from s to t. No\\nefficient algorithm is known to find a shortest descending path (SDP) from s to\\nt in a polyhedral terrain. We give a simple approximation algorithm that solves\\nthe SDP problem on general terrains. Our algorithm discretizes the terrain with\\nO(n^2 X / e) Steiner points so that after an O(n^2 X / e * log(n X /e))-time\\npreprocessing phase for a given vertex s, we can determine a (1+e)-approximate\\nSDP from s to any point v in O(n) time if v is either a vertex of the terrain\\nor a Steiner point, and in O(n X /e) time otherwise. Here n is the size of the\\nterrain, and X is a parameter of the geometry of the terrain.\\n', '  The best deterministic unconditionally proven integer factorization\\nalgorithms have exponential running time complexities of O(N^(1/4)) arithmetic\\noperations, and conditional on the Riemann hypothesis, there is a deterministic\\nalgorithm of exponential running time complexity O(N^(1/5)). This note proposes\\na new deterministic integer factorization algorithm of deterministic\\nexponential time complexity O(N^(1/6)). Furthermore, an algorithm for\\ndecomposing composite integers that have factor differences of the form q - p =\\n(r - 1)N^(1/2) + u, where r > 1 is a fixed parameter, and | u | < N^(1/3), in\\ndeterministic logarithmic time and various other results are included.\\n', '  We consider non-negative solutions of the fast diffusion equation $u_t=\\\\Delta\\nu^m$ with $m \\\\in (0,1)$, in the Euclidean space R^d, d?3, and study the\\nasymptotic behavior of a natural class of solutions, in the limit corresponding\\nto $t\\\\to\\\\infty$ for $m\\\\ge m_c=(d-2)/d$, or as t approaches the extinction time\\nwhen m < mc. For a class of initial data we prove that the solution converges\\nwith a polynomial rate to a self-similar solution, for t large enough if $m\\\\ge\\nm_c$, or close enough to the extinction time if m < mc. Such results are new in\\nthe range $m\\\\le m_c$ where previous approaches fail. In the range mc < m < 1 we\\nimprove on known results.\\n', \"  In this paper we prove local results for solutions to the Ricci flow (heat\\nflow) whose speed (height) is bounded by $\\\\frac c t$ for some time interval $ t\\n\\\\in (0,T)$. These results are contained in chapter 7 of the author's\\nhabilitation thesis, University of Freiburg, Germany, 2006.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "print(contexto_bm25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a811a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a8725",
   "metadata": {},
   "source": [
    "### Respuesta TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79c00d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tÃ©rmino \"computer\" en el contexto proporcionado se refiere principalmente a dos tipos: la computadora clÃ¡sica y la computadora cuÃ¡ntica. \n",
      "\n",
      "Una computadora cuÃ¡ntica es una mÃ¡quina que puede realizar ciertos cÃ¡lculos mucho mÃ¡s rÃ¡pido que una computadora clÃ¡sica gracias a las leyes de la mecÃ¡nica cuÃ¡ntica. Sin embargo, estas computadoras aÃºn no existen plenamente, ya que es extremadamente difÃ­cil controlar sistemas mecÃ¡nico-cuÃ¡nticos con el grado necesario. Se considera que tecnologÃ­as maduras de procesamiento de informaciÃ³n cuÃ¡ntica podrÃ­an utilizar luz (fotones) como portadores ideales de informaciÃ³n cuÃ¡ntica.\n",
      "\n",
      "AdemÃ¡s, se menciona un concepto llamado \"computadora de dualidad\" que es una computadora cuÃ¡ntica en movimiento que aprovecha la dualidad onda-partÃ­cula y ofrece un poder adicional de cÃ³mputo mediante un paralelismo llamado \"dualidad paralelismo\". Por ejemplo, una computadora de dualidad con n-dubits puede ser modelada por una computadora cuÃ¡ntica con n+1 qubits.\n",
      "\n",
      "Finalmente, tambiÃ©n se hace referencia a la simulaciÃ³n de algoritmos cuÃ¡nticos en una computadora clÃ¡sica mediante programaciÃ³n, y a un paquete en C++ llamado ACTIVIA para cÃ¡lculos relacionados con la activaciÃ³n de rayos cÃ³smicos y producciÃ³n de isÃ³topos, lo que es un ejemplo de aplicaciÃ³n computacional en fÃ­sica.\n",
      "\n",
      "Si deseas informaciÃ³n mÃ¡s especÃ­fica, por favor indÃ­came a quÃ© aspecto del tÃ©rmino \"computer\" te refieres.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Eres una aplicacion de Retrieval Augmented Generation que siempre responde en espaÃ±ol.\n",
    "Usa el siguiente contexto para responder a la pregunta del usuario.\n",
    "Si la respuesta no se encuentra en el contexto, responde \"No tengo suficiente informaciÃ³n para responder a esa pregunta\".\n",
    "\n",
    "Contexto:\n",
    "{contexto_tfidf}\n",
    "\n",
    "Pregunta:\n",
    "El usuario esta preguntando sobre \"{query}\".\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "686cc948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tengo suficiente informaciÃ³n para responder a esa pregunta.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Eres una aplicacion de Retrieval Augmented Generation que siempre responde en espaÃ±ol.\n",
    "Usa el siguiente contexto para responder a la pregunta del usuario.\n",
    "Si la respuesta no se encuentra en el contexto, responde \"No tengo suficiente informaciÃ³n para responder a esa pregunta\".\n",
    "\n",
    "Contexto:\n",
    "{contexto_bm25}\n",
    "\n",
    "Pregunta:\n",
    "El usuario esta preguntando sobre \"{query}\".\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44f58f",
   "metadata": {},
   "source": [
    "### Respuesta FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "018c249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El contexto proporciona varias referencias al uso de computadoras en diferentes Ã¡reas, como la adquisiciÃ³n de datos para experimentos de fÃ­sica, la importancia Ã©tica en la investigaciÃ³n en ciencias de la computaciÃ³n, la visualizaciÃ³n grÃ¡fica para tareas cientÃ­ficas y de ingenierÃ­a, y la precisiÃ³n limitada en cÃ¡lculos numÃ©ricos cientÃ­ficos usando computadoras. \n",
      "\n",
      "Si te refieres a algÃºn aspecto especÃ­fico sobre \"Computer\" o computadoras, por favor indÃ­came para poder ayudarte mejor con la informaciÃ³n disponible.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Eres una aplicacion de Retrieval Augmented Generation que siempre responde en espaÃ±ol.\n",
    "Usa el siguiente contexto para responder a la pregunta del usuario.\n",
    "Si la respuesta no se encuentra en el contexto, responde \"No tengo suficiente informaciÃ³n para responder a esa pregunta\".\n",
    "\n",
    "Contexto:\n",
    "{contexto_faiss}\n",
    "\n",
    "Pregunta:\n",
    "El usuario esta preguntando sobre \"{query}\".\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e5be5",
   "metadata": {},
   "source": [
    "## Evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b97ca5",
   "metadata": {},
   "source": [
    "### Documentos presentados por tfidf y faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08401e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      identifier                                              title  \\\n",
      "1216   0704.1217                The Manin conjecture in dimension 2   \n",
      "7283   0705.3281          Del Pezzo singularities and SUSY breaking   \n",
      "10293  0706.1607  Partitions with independent iterates in random...   \n",
      "23264  0709.0999  Classification of Toric log Del Pezzo Surfaces...   \n",
      "25858  0709.3593  Noncommutative del Pezzo surfaces and Calabi-Y...   \n",
      "\n",
      "                                                abstract  \n",
      "1216     These lecture notes describe the current sta...  \n",
      "7283     An analytic construction of compact Calabi-Y...  \n",
      "10293    Consider an invertible measure-preserving tr...  \n",
      "23264    Toric log Del Pezzo surfaces with Picard num...  \n",
      "25858    The hypersurface in a 3-dimensional vector s...  \n",
      "      identifier                                              title  \\\n",
      "5155   0705.1153  Optical Sky Brightness at Cerro Tololo Inter-A...   \n",
      "12307  0706.3621                     Climate Change: The Sun's Role   \n",
      "12406  0706.3720         How Can We Avert Dangerous Climate Change?   \n",
      "14446  0707.1276  Quantitative implications of the secondary rol...   \n",
      "24375  0709.2110  The climate version of the Eta regional foreca...   \n",
      "\n",
      "                                                abstract  \n",
      "5155     We present optical UBVRI sky brightness meas...  \n",
      "12307    The sun's role in the earth's recent warming...  \n",
      "12406    Recent analyses indicate that the amount of ...  \n",
      "14446    A review of the recent refereed literature f...  \n",
      "24375    The regional climate model prepared from Eta...  \n"
     ]
    }
   ],
   "source": [
    "def get_relevant_docs_df(similar_docs):\n",
    "    relevant_df = corpus_df[corpus_df['raw'].isin(similar_docs)][['identifier', 'title', 'raw']]\n",
    "    relevant_df = relevant_df.rename(columns={'raw': 'abstract'})\n",
    "    return relevant_df\n",
    "\n",
    "relevant_tfidf_df = get_relevant_docs_df(contexto_tfidf)\n",
    "relevant_bm25_df = get_relevant_docs_df(contexto_bm25)\n",
    "relevant_faiss_df = get_relevant_docs_df(contexto_faiss)\n",
    "\n",
    "print(relevant_tfidf_df)\n",
    "print(relevant_faiss_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
