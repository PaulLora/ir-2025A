{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849354a7",
   "metadata": {},
   "source": [
    "# Recuperacion de la Informaicon\n",
    "# Examen Segundo Bimestre RI\n",
    "\n",
    "**Nombre:** Paul Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56578d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f342bcbb",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a37255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "titles = []\n",
    "identifiers = []\n",
    "with open(\"../data/examen/data.json\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            entry = json.loads(line)\n",
    "            title = entry.get(\"title\", \"\")\n",
    "            abstract = entry.get(\"abstract\", \"\")\n",
    "            identifier = entry.get(\"id\", \"\")\n",
    "            corpus.append(abstract)\n",
    "            titles.append(title)\n",
    "            identifiers.append(identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e67aaca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_df = pd.DataFrame({\n",
    "    \"identifier\": identifiers,\n",
    "    \"title\": titles,\n",
    "    \"raw\": corpus,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "141f8ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess_doc(doc):\n",
    "    words = word_tokenize(doc.lower())\n",
    "    words_filtered = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    return ' '.join(words_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14378bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>title</th>\n",
       "      <th>raw</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0704.0001</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>fully differential calculation perturbative qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0704.0002</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>describe new algorithm k game colors use obtai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0704.0003</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>evolution system described dark matter field f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0704.0004</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>show determinant stirling cycle numbers counts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0704.0005</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>paper show compute norm using dyadic grid resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27918</th>\n",
       "      <td>0710.0971</td>\n",
       "      <td>The Extending for Composite Skyrme Model</td>\n",
       "      <td>In this paper, we have extended the composit...</td>\n",
       "      <td>paper extended composite skyrme model proposed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27919</th>\n",
       "      <td>0710.0972</td>\n",
       "      <td>A Floer homology for exact contact embeddings</td>\n",
       "      <td>In this paper we construct the Floer homolog...</td>\n",
       "      <td>paper construct floer homology action function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27920</th>\n",
       "      <td>0710.0973</td>\n",
       "      <td>Modulation invariant bilinear T(1) theorem</td>\n",
       "      <td>We prove a T(1) theorem for bilinear singula...</td>\n",
       "      <td>prove theorem bilinear singular integral opera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27921</th>\n",
       "      <td>0710.0974</td>\n",
       "      <td>Hawking radiation in GHS and non-extremal D1-D...</td>\n",
       "      <td>We apply the method of Banerjee and Kulkarni...</td>\n",
       "      <td>apply method banerjee kulkarni provide derivat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27922</th>\n",
       "      <td>0710.0975</td>\n",
       "      <td>Renormalisation of quark bilinears with Nf=2 W...</td>\n",
       "      <td>We present results for the renormalisation c...</td>\n",
       "      <td>present results renormalisation constants bili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27923 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      identifier                                              title  \\\n",
       "0      0704.0001  Calculation of prompt diphoton production cros...   \n",
       "1      0704.0002           Sparsity-certifying Graph Decompositions   \n",
       "2      0704.0003  The evolution of the Earth-Moon system based o...   \n",
       "3      0704.0004  A determinant of Stirling cycle numbers counts...   \n",
       "4      0704.0005  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "...          ...                                                ...   \n",
       "27918  0710.0971           The Extending for Composite Skyrme Model   \n",
       "27919  0710.0972      A Floer homology for exact contact embeddings   \n",
       "27920  0710.0973         Modulation invariant bilinear T(1) theorem   \n",
       "27921  0710.0974  Hawking radiation in GHS and non-extremal D1-D...   \n",
       "27922  0710.0975  Renormalisation of quark bilinears with Nf=2 W...   \n",
       "\n",
       "                                                     raw  \\\n",
       "0        A fully differential calculation in perturba...   \n",
       "1        We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2        The evolution of Earth-Moon system is descri...   \n",
       "3        We show that a determinant of Stirling cycle...   \n",
       "4        In this paper we show how to compute the $\\L...   \n",
       "...                                                  ...   \n",
       "27918    In this paper, we have extended the composit...   \n",
       "27919    In this paper we construct the Floer homolog...   \n",
       "27920    We prove a T(1) theorem for bilinear singula...   \n",
       "27921    We apply the method of Banerjee and Kulkarni...   \n",
       "27922    We present results for the renormalisation c...   \n",
       "\n",
       "                                               processed  \n",
       "0      fully differential calculation perturbative qu...  \n",
       "1      describe new algorithm k game colors use obtai...  \n",
       "2      evolution system described dark matter field f...  \n",
       "3      show determinant stirling cycle numbers counts...  \n",
       "4      paper show compute norm using dyadic grid resu...  \n",
       "...                                                  ...  \n",
       "27918  paper extended composite skyrme model proposed...  \n",
       "27919  paper construct floer homology action function...  \n",
       "27920  prove theorem bilinear singular integral opera...  \n",
       "27921  apply method banerjee kulkarni provide derivat...  \n",
       "27922  present results renormalisation constants bili...  \n",
       "\n",
       "[27923 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df['processed'] = corpus_df['raw'].apply(preprocess_doc)\n",
    "corpus_df['processed'] = corpus_df['processed'].str.replace(\"\\n\", \" \")\n",
    "corpus_df['processed'] = corpus_df['processed'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de4348",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "728f4692",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_processed_list = corpus_df['processed'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7412be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfidf_vectorizer_vectors=tfidf_vectorizer.fit_transform(corpus_processed_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9732609b",
   "metadata": {},
   "source": [
    "### Indexacion TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "95c7ac83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27913</th>\n",
       "      <th>27914</th>\n",
       "      <th>27915</th>\n",
       "      <th>27916</th>\n",
       "      <th>27917</th>\n",
       "      <th>27918</th>\n",
       "      <th>27919</th>\n",
       "      <th>27920</th>\n",
       "      <th>27921</th>\n",
       "      <th>27922</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aab</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aac</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aadl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aadt</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzgam</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzgamma</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzh</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41207 rows × 27923 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1      2      3      4      5      6      7      8      9      \\\n",
       "aa         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aab        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aac        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadl       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadt       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "zz         0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgam      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgamma    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzh        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzz        0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         ...  27913  27914  27915  27916  27917  27918  27919  27920  27921  \\\n",
       "aa       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aab      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aac      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadl     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "aadt     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "zz       ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgam    ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzgamma  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzh      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "zzz      ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "         27922  \n",
       "aa         0.0  \n",
       "aab        0.0  \n",
       "aac        0.0  \n",
       "aadl       0.0  \n",
       "aadt       0.0  \n",
       "...        ...  \n",
       "zz         0.0  \n",
       "zzgam      0.0  \n",
       "zzgamma    0.0  \n",
       "zzh        0.0  \n",
       "zzz        0.0  \n",
       "\n",
       "[41207 rows x 27923 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tfidf_vectorizer_vectors.T.todense(), index=tfidf_vectorizer.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8b301e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_docs_tfidf(query, top_k=10):\n",
    "    vertorized_query = tfidf_vectorizer.transform([query])\n",
    "    cosine_similarities = cosine_similarity(vertorized_query, tfidf_vectorizer_vectors).flatten()\n",
    "    top_indices = cosine_similarities.argsort()[-top_k:][::-1]\n",
    "    return corpus_df.iloc[top_indices]['raw'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c3f296",
   "metadata": {},
   "source": [
    "## Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4791663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(corpus_df[\"processed\"].tolist(), convert_to_numpy=True)\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)\n",
    "\n",
    "corpus_df['faiss_embeddings'] = embeddings.tolist()\n",
    "corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d0fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_docs_faiss(index, query, top_k=10):\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    _, indices = index.search(query_embedding, top_k)\n",
    "    return corpus_df.iloc[indices.flatten()]['raw'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c96b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abeff117",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca627523",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Impacto del cambio climatico\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2d4010",
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto_tfidf = similar_docs_tfidf(query, top_k=5)\n",
    "contexto_faiss = similar_docs_faiss(index, query, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014a8725",
   "metadata": {},
   "source": [
    "### Respuesta TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c00d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No tengo suficiente información para responder a esa pregunta.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Eres una aplicacion de Retrieval Augmented Generation que siempre responde en español.\n",
    "Usa el siguiente contexto para responder a la pregunta del usuario.\n",
    "Si la respuesta no se encuentra en el contexto, responde \"No tengo suficiente información para responder a esa pregunta\".\n",
    "\n",
    "Contexto:\n",
    "{contexto_tfidf}\n",
    "\n",
    "Pregunta:\n",
    "El usuario esta preguntando sobre \"{query}\".\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b44f58f",
   "metadata": {},
   "source": [
    "### Respuesta FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El cambio climático tiene un impacto negativo en la biodiversidad, ya que puede llevar a la pérdida de muchas especies debido a cambios en las zonas climáticas, acidificación de los océanos y la desintegración de glaciares que afectan el suministro de agua para millones de personas. Además, el calentamiento global y sus efectos asociados pueden provocar la extinción masiva de especies, alterando profundamente el \"árbol de la vida\" en un futuro cercano. Por lo tanto, es crucial mantener los niveles de CO2 bajos para evitar estos daños significativos a la biodiversidad.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Eres una aplicacion de Retrieval Augmented Generation que siempre responde en español.\n",
    "Usa el siguiente contexto para responder a la pregunta del usuario.\n",
    "Si la respuesta no se encuentra en el contexto, responde \"No tengo suficiente información para responder a esa pregunta\".\n",
    "\n",
    "Contexto:\n",
    "{contexto_faiss}\n",
    "\n",
    "Pregunta:\n",
    "El usuario esta preguntando sobre \"{query}\".\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=prompt\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426e5be5",
   "metadata": {},
   "source": [
    "## Evaluacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b97ca5",
   "metadata": {},
   "source": [
    "### Documentos presentados por tfidf y faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08401e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      identifier                                              title  \\\n",
      "10358  0706.1672  Resonant phenomena in extended chaotic systems...   \n",
      "12307  0706.3621                     Climate Change: The Sun's Role   \n",
      "15742  0707.2572  Noise effects in extended chaotic system: stud...   \n",
      "19998  0708.2147  The logistic equation and a critique of the th...   \n",
      "24375  0709.2110  The climate version of the Eta regional foreca...   \n",
      "\n",
      "                                                abstract  \n",
      "10358    We investigate the effects of a time-correla...  \n",
      "12307    The sun's role in the earth's recent warming...  \n",
      "15742    We investigate the effects of a time-correla...  \n",
      "19998    Species coexistence is one of the central th...  \n",
      "24375    The regional climate model prepared from Eta...  \n",
      "      identifier                                              title  \\\n",
      "2648   0704.2649  Hedging our bets: the expected contribution of...   \n",
      "12307  0706.3621                     Climate Change: The Sun's Role   \n",
      "12406  0706.3720         How Can We Avert Dangerous Climate Change?   \n",
      "19998  0708.2147  The logistic equation and a critique of the th...   \n",
      "22482  0709.0217  Mobility promotes and jeopardizes biodiversity...   \n",
      "\n",
      "                                                abstract  \n",
      "2648     If predictions for species extinctions hold,...  \n",
      "12307    The sun's role in the earth's recent warming...  \n",
      "12406    Recent analyses indicate that the amount of ...  \n",
      "19998    Species coexistence is one of the central th...  \n",
      "22482    Biodiversity is essential to the viability o...  \n"
     ]
    }
   ],
   "source": [
    "def get_relevant_docs_df(similar_docs):\n",
    "    relevant_df = corpus_df[corpus_df['raw'].isin(similar_docs)][['identifier', 'title', 'raw']]\n",
    "    relevant_df = relevant_df.rename(columns={'raw': 'abstract'})\n",
    "    return relevant_df\n",
    "\n",
    "relevant_tfidf_df = get_relevant_docs_df(contexto_tfidf)\n",
    "relevant_faiss_df = get_relevant_docs_df(contexto_faiss)\n",
    "\n",
    "print(relevant_tfidf_df)\n",
    "print(relevant_faiss_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
